{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "09e8d8fd",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasrourTawfik/DFMEA-LLM-Enhanced/blob/main/Documentation/colabs/affinage_par_ludwig_notebook_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13277c78",
      "metadata": {
        "id": "13277c78"
      },
      "source": [
        "# Affinage par LUDWIG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ec2f30d",
      "metadata": {
        "id": "0ec2f30d"
      },
      "source": [
        "![LUDWIG framework](https://github.com/MasrourTawfik/DFMEA-LLM-Enhanced/blob/main/Documentation/images/Ludwig.png?raw=1)\n",
        "\n",
        "\n",
        "Cette section explique comment effectuer le fine-tuning d'un modèle de langage en utilisant Ludwig, un outil puissant qui simplifie le cycle de vie de l'apprentissage automatique. Le processus implique l'utilisation d'une configuration de modèle spécifique et d'un ensemble de données pour adapter un modèle pré-entraîné à une tâche spécialisée."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace7b0a4",
      "metadata": {
        "id": "ace7b0a4"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Avant de commencer, assurez-vous que Ludwig est installé et configuré dans votre environnement. Vous devrez également configurer le token du Hugging Face Hub pour accéder aux modèles pré-entraînés. Ceci est réalisé en définissant la variable d'environnement HUGGING_FACE_HUB_TOKEN avec votre clé API Hugging Face :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e4c1ef9",
      "metadata": {
        "id": "3e4c1ef9"
      },
      "source": [
        "Ludwig nécessite une configuration YAML qui décrit les paramètres du modèle et de l'entraînement. Les éléments clés de cette configuration incluent :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac06e16",
      "metadata": {
        "id": "bac06e16"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Le dataset qu'on a utilisé dans cet exemple c'est Alpaca, c'est une ressource unique destinée à l'entraînement et au fine-tuning des modèles de langue pour mieux suivre **les instructions**.\n",
        "\n",
        "[Alpaca dataset](https://huggingface.co/datasets/tatsu-lab/alpaca)\n",
        "\n",
        "![DATASET Alpaca](https://github.com/MasrourTawfik/DFMEA-LLM-Enhanced/blob/main/Documentation/images/alpaca.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed24a23",
      "metadata": {
        "id": "3ed24a23"
      },
      "source": [
        "## Entraînement\n",
        "\n",
        "Pour entraîner le modèle, chargez la configuration et spécifiez l'ensemble de données. La classe LudwigModel est utilisée avec la méthode train :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c27f0336",
      "metadata": {
        "id": "c27f0336"
      },
      "source": [
        "## Sauvegarde du Modèle\n",
        "\n",
        "Après l'entraînement, sauvegardez le modèle pour une utilisation ou un déploiement ultérieurs :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48fdde9",
      "metadata": {
        "id": "d48fdde9"
      },
      "outputs": [],
      "source": [
        "!pip install ludwig ludwig[llm] peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce489268",
      "metadata": {
        "id": "ce489268"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv('HUGGINGFACE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed79be67",
      "metadata": {
        "id": "ed79be67"
      },
      "outputs": [],
      "source": [
        "# Ludwig configuration\n",
        "config_str = \"\"\"\n",
        "model_type: llm\n",
        "base_model: mistralai/Mistral-7B-v0.1\n",
        "# base_model: alexsherstinsky/Mistral-7B-v0.1-sharded\n",
        "# base_model: Siddharthvij10/MistralSharded2\n",
        "quantization:\n",
        "  bits: 4\n",
        "adapter:\n",
        "  type: lora\n",
        "prompt:\n",
        "  template: |\n",
        "    ### Instruction:\n",
        "    {instruction}\n",
        "    ### Input:\n",
        "    {input}\n",
        "    ### Response:\n",
        "input_features:\n",
        "  - name: prompt\n",
        "    type: text\n",
        "    preprocessing:\n",
        "      max_sequence_length: 256\n",
        "output_features:\n",
        "  - name: output\n",
        "    type: text\n",
        "    preprocessing:\n",
        "      max_sequence_length: 256\n",
        "trainer:\n",
        "  type: finetune\n",
        "  learning_rate: 0.0001\n",
        "  batch_size: 1\n",
        "  gradient_accumulation_steps: 16\n",
        "  epochs: 3\n",
        "  learning_rate_scheduler:\n",
        "    warmup_fraction: 0.01\n",
        "preprocessing:\n",
        "  sample_ratio: 0.1\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c5a6bb2",
      "metadata": {
        "id": "0c5a6bb2"
      },
      "outputs": [],
      "source": [
        "from ludwig.api import LudwigModel\n",
        "import yaml\n",
        "import logging\n",
        "\n",
        "\n",
        "config = yaml.safe_load(config_str)\n",
        "model = LudwigModel(config=config, logging_level=logging.INFO)\n",
        "results = model.train(dataset=\"ludwig://alpaca\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246c702b",
      "metadata": {
        "id": "246c702b"
      },
      "outputs": [],
      "source": [
        "model.save(\"results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55cc7046",
      "metadata": {
        "id": "55cc7046"
      },
      "outputs": [],
      "source": [
        "!python -m ludwig.upload hf_hub --repo_id \"your_repo_id\" --model_path \"path_to_your_model\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

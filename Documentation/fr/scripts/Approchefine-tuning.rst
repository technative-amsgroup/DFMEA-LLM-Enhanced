Approche fine tuning üîß
=====================

Collecte des donn√©es üìä
^^^^^^^^^^^^^^^^

Pour recueillir les donn√©es destin√©es √† l‚Äôentra√Ænement de nos mod√®les, nous avons
exploit√© la plateforme Kaggle Kaggle [2024] qui constitue une base de donn√©es en
ligne d√©di√©e aux projets de Data Science. Cette plateforme nous a donn√© acc√®s √† cinquante ensembles de donn√©es distincts portant sur les avis de clients concernant cinquante marques de v√©hicules diff√©rentes. Tous ces ensembles de donn√©es pr√©sentent
une structure uniforme avec les m√™mes noms de colonnes, comprenant notamment :
- **Review_Date** : La date √† laquelle l‚Äôauteur a publi√© son avis.
- **Author_Name** : Le nom de l‚Äôauteur ayant r√©dig√© l‚Äôavis sur le v√©hicule.
- **Vehicle_Title** : Le titre ou le nom du v√©hicule objet de l‚Äôavis.
- **Review_Title** : Le titre donn√© par l‚Äôauteur √† son avis, offrant un aper√ßu du
contenu.
- **Review** : Le texte d√©taill√© de l‚Äôavis r√©dig√© par l‚Äôauteur sur le v√©hicule.
- **Rating** : La notation attribu√©e par l‚Äôauteur pour √©valuer le v√©hicule, g√©n√©ralement sur une √©chelle (par exemple, de 1 √† 5 √©toiles).
Ces colonnes renferment des informations cruciales sur les avis relatifs aux v√©hicules, telles que la date de publication, l‚Äôauteur, le v√©hicule concern√©, le titre de
l‚Äôavis, le contenu de celui-ci, ainsi que la note attribu√©e

Traitement des donn√©es 
^^^^^^^^^^^^^^^^^^

√âtiquetage
-------------

Cette phase du projet rev√™t une importance cruciale, car
elle implique la cr√©ation de notre colonne cible ("Target") qui stockera les listes de
pi√®ces de v√©hicules. Pour ce faire, nous avons effectu√© du web scraping sur deux
sites web : wikipedia.com [wik] et listexplained.com [lis]. Ces sites nous ont fourni
un acc√®s √† une liste non exhaustive de pi√®ces de v√©hicules, totalisant environ sept
cents r√©f√©rences. Nous sommes conscients que notre liste ne couvre pas toutes les
pi√®ces de v√©hicules et ne prend pas en compte toutes les appellations possibles pour
une m√™me pi√®ce. Cependant, pour le moment, nous nous en tiendrons √† cela et nous
am√©liorerons notre liste au fil de notre progression.
Pour conclure cette phase d‚Äô√©tiquetage, nous avons parcouru l‚Äôensemble de notre
ensemble de donn√©es, cr√©ant ainsi deux nouvelles colonnes :
- "List_part" : qui contient une liste des pi√®ces de v√©hicules trouv√©es dans
chaque avis.
- "Count_part" : qui indique le nombre de pi√®ces pr√©sentes dans chaque avis.
√Ä ce stade, nous pouvons affirmer que notre ensemble de donn√©es est en bonne
voie et que nous sommes pr√™ts √† passer √† l‚Äô√©tape du fine-tuning.

Pr√©paration du dataset pour le fine-tuning
---------------------------

Une fois que nous avons
d√©termin√© que le fine-tuning est la solution appropri√©e, indiquant que notre prompt
a √©t√© optimis√© au mieux de ses capacit√©s et que des probl√®mes persistants avec le
mod√®le ont √©t√© identifi√©s, il est imp√©ratif de pr√©parer les donn√©es pour l‚Äôentra√Ænement
du mod√®le. Dans cette √©tape cruciale, nous devons constituer un ensemble vari√© de
conversations de d√©monstration, similaires aux conversations auxquelles nous demanderons au mod√®le de r√©pondre lors de l‚Äôinf√©rence en production.
Chaque exemple dans notre jeu de donn√©es doit √™tre une conversation structur√©e
selon le m√™me format que notre API de compl√©tion de chat, comprenant une liste
de messages o√π chaque message a un r√¥le, un contenu et √©ventuellement un nom. Il
est essentiel d‚Äôinclure dans ces exemples d‚Äôentra√Ænement des situations o√π le mod√®le
sollicit√© ne se comporte pas comme souhait√©. Les messages fournis en tant qu‚Äôassistant dans les donn√©es doivent repr√©senter les r√©ponses id√©ales que nous souhaitons
que le mod√®le fournisse.
Cette approche garantit que le mod√®le est form√© sur des exemples diversifi√©s et
sp√©cifiques, incluant des cas o√π des am√©liorations sont n√©cessaires. Cela permet de
guider le mod√®le vers les r√©ponses id√©ales que nous attendons dans des situations
vari√©es lors de l‚Äôutilisation du mod√®le en production.
La derni√®re √©tape consiste √† formater notre dataset, pour cela nous avons ajout√©
une s√©quence de fin √† tous les prompts : il termine par la chaine de caract√®re "->
" qui indique au mod√®le qu‚Äôil peut commencer √† faire la compl√©tion c‚Äôest-√†-dire g√©n√©rer la liste des pi√®ces ; et une s√©quence de fin, toutes les compl√©tions se termine
par le mot " END" pour indiquer au mod√®le qu‚Äôil doit s‚Äôarr√™ter, on fait cela pour
√©viter que le mod√®le ne continue de g√©n√©rer des mots non souhait√©s. Et maintenant
nous convertissons notre dataset en fichier Jsonl qui sera le format utilis√© pour le
fine-tuning

Entrainement des Mod√®les
^^^^^^^^^^^^^^^^^^

Apr√®s avoir minutieusement pr√©par√© et format√© nos donn√©es, nous entamons la
phase d‚Äôentra√Ænement, cruciale pour la cr√©ation du mod√®le. Pour ce faire, nous utilisons l‚Äôoutil en ligne de commande (CLI) d‚ÄôOpenAI, ex√©cutant ainsi une s√©rie de
commandes. Nos donn√©es sont ensuite t√©l√©charg√©es, accompagn√©es des hyperparam√®tres que nous avons d√©finis, et le processus d‚Äôentra√Ænement est enclench√©.
Dans notre approche, nous avons choisi un processus d‚Äôentra√Ænement it√©ratif
qui permet un ajustement continu du mod√®le, affinant ses performances de mani√®re constante. Cette m√©thodologie de fine-tuning it√©ratif implique plusieurs cycles
d‚Äôam√©lioration du mod√®le, contrastant avec une seule it√©ration de fine-tuning. Nous
adaptons progressivement notre mod√®le, perfectionnant ses performances au fil des
it√©rations.
L‚Äôobjectif principal de ce projet est de former un mod√®le polyvalent capable
d‚Äôaccomplir diverses t√¢ches de d√©tection, notamment la reconnaissance des noms
de pi√®ces, l‚Äôidentification des probl√®mes li√©s aux pi√®ces ou les d√©fauts, ainsi que la
compr√©hension du contexte. Initialement, nos efforts se concentrent exclusivement
sur la d√©tection des noms de pi√®ces, puis nous int√©grerons progressivement les autres
objectifs au fil du temps.

.. image:: ../images/itterative.png
    :width: 90%
    :align: center
    :alt: itterative

√âvaluation des mod√®les
^^^^^^^^^^^^^^^^

Notre premier mod√®le, partfinder_t_001, a √©t√© entra√Æn√© sur 1000 lignes de notre
ensemble de donn√©es, repr√©sentant ainsi 5,56% du total. √Ä la suite de l‚Äôentra√Ænement,
les performances du mod√®le sont accessibles dans un fichier results.csv. Ce fichier
contient une ligne pour chaque √©tape d‚Äôentra√Ænement, o√π une √©tape fait r√©f√©rence √†
une passe avant et arri√®re sur un lot de donn√©es.
- elapsed_tokens : le nombre de jetons que le mod√®le a trait√©s jusqu‚Äô√† pr√©sent
(y compris les r√©p√©titions)
- elapsed_examples : le nombre d‚Äôexemples que le mod√®le a trait√©s jusqu‚Äô√†
pr√©sent (y compris les r√©p√©titions), un exemple correspondant √† un √©l√©ment
du lot (batch). Par exemple, avec batch_size = 4, chaque √©tape augmentera
elapsed_examples de 4.
- training_loss : la perte (loss) sur le lot d‚Äôentra√Ænement
- training_sequence_accuracy : le pourcentage de compl√©tions dans le lot
d‚Äôentra√Ænement pour lesquelles les jetons pr√©dits par le mod√®le correspondent
exactement aux jetons de compl√©tion r√©els.
- training_token_accuracy : le pourcentage de jetons dans le lot d‚Äôentra√Ænement qui ont √©t√© pr√©dits correctement par le mod√®le.
L‚Äô√©volution des performances de notre mod√®le √† chaque √©tape de son entra√Ænement est pr√©sent√©e sur les figures ci-dessous.


.. image:: ../images/result.png
    :width: 100%
    :align: center
    :alt: result
..

